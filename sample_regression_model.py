# -*- coding: utf-8 -*-
"""Sample regression model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oznzkgNv2AWyYHd9syki3e20PPqcjrdw
"""

# Import required libraries
import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Read in the insuarance dataset
insuarance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')
insuarance

# Let`s try to one hot encode our data with pandas get_dummie() function
insuarance_one_hot=pd.get_dummies(insuarance)
insuarance_one_hot

# Create X and y values (features and labels)

X = insuarance_one_hot.drop('charges', axis=1)
y = insuarance_one_hot['charges']
X.head(), y.head()

# Spliting data with scikit learn
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build a neural network
tf.random.set_seed(42)

 # Build the model
insuarance_model = tf.keras.Sequential([
    tf.keras.layers.Dense(10),
    tf.keras.layers.Dense(1)
 ])

 # Compile the model
insuarance_model.compile(
    loss = tf.keras.losses.mae,
    optimizer = tf.keras.optimizers.SGD(),
    metrics = ['mae']
 )

insuarance_model.fit(X_train, y_train, epochs=100)

# Evaluate the results of the insuarance model against the test data
insuarance_model.evaluate(X_test,y_test)

"""### Improving our model
To improve our model, we`ll learn several experiments:

1. Add an extra layer with more hidden units
2. Train for longer
"""

tf.random.set_seed(42)

# Build the model
insuarance_model_2 = tf.keras.Sequential([
    tf.keras.layers.Dense(100),
    tf.keras.layers.Dense(10),
    tf.keras.layers.Dense(1)
])

# Compile the model
insuarance_model_2.compile(
    loss = tf.keras.losses.mae,
    optimizer = tf.keras.optimizers.SGD(),
    metrics = ['mae']
)

# Fit the model
insuarance_model_2.fit(X_train,y_train, epochs=100)

"""Notice the loss and mae are non, this could mean alot of things, maybe our model was to complex and fed on small data.

Now lets try to tweak something else maybe on the compiling area, maybe we change the optimizer and keep everything else
"""

tf.random.set_seed(42)

# Build the model
insuarance_model_2 = tf.keras.Sequential([
    tf.keras.layers.Dense(100),
    tf.keras.layers.Dense(10),
    tf.keras.layers.Dense(1)
])

# Compile the model
insuarance_model_2.compile(
    loss = tf.keras.losses.mae,
    optimizer = tf.keras.optimizers.Adam(),
    metrics = ['mae']
)

# Fit the model
insuarance_model_2.fit(X_train,y_train, epochs=100)

# Evaluate the model
insuarance_model_2.evaluate(X_test,y_test)

# Compare this model to the previous one
insuarance_model_2.evaluate(X_test,y_test),insuarance_model.evaluate(X_test,y_test)

"""Here we could see that there is an increment from the previous model by looking at the loss and mae

### Build our 3rd model
"""

tf.random.set_seed(42)

# Build the model
insuarance_model_3 = tf.keras.Sequential([
    tf.keras.layers.Dense(100),
    tf.keras.layers.Dense(10),
    tf.keras.layers.Dense(1)
])

# Compile the model
insuarance_model_3.compile(
    loss = tf.keras.losses.mae,
    optimizer = tf.keras.optimizers.Adam(),
    metrics = ['mae']
)

# Fit the model
history = insuarance_model_3.fit(X_train,y_train,epochs=200)

# Evaluate our 3rd model
insuarance_model_3.evaluate(X_test,y_test)

# Compare the 3rd model with the other models
insuarance_model_3.evaluate(X_test,y_test),insuarance_model_2.evaluate(X_test,y_test),insuarance_model.evaluate(X_test,y_test)

"""Here we see that the 3rd model definetly did the best since it has the lowest loss and mae value"""

# Plot history (also known as loss curve or training curve)
pd.DataFrame(history.history).plot()
plt.ylabel('loss')
plt.xlabel('epochs')

